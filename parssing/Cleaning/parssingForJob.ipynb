{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/jobs_dataset_with_features.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Role</th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Social Media Manager</td>\n",
       "      <td>5 to 15 Years Digital Marketing Specialist M.T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Frontend Web Developer</td>\n",
       "      <td>2 to 12 Years Web Developer BCA HTML, CSS, Jav...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Role                                           Features\n",
       "0    Social Media Manager  5 to 15 Years Digital Marketing Specialist M.T...\n",
       "1  Frontend Web Developer  2 to 12 Years Web Developer BCA HTML, CSS, Jav..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Role', 'Features'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Role\n",
       "Interaction Designer          20580\n",
       "Network Administrator         17470\n",
       "User Interface Designer       14036\n",
       "Social Media Manager          13945\n",
       "User Experience Designer      13935\n",
       "                              ...  \n",
       "Benefits Coordinator           6839\n",
       "Research Analyst               6830\n",
       "Administrative Coordinator     6803\n",
       "IT Support Specialist          6799\n",
       "UI/UX Designer                 6743\n",
       "Name: count, Length: 61, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping classes with less than 4000 instances\n",
    "min_count = 4000\n",
    "role_counts = df['Role'].value_counts()\n",
    "dropped_classes = role_counts[role_counts < min_count].index\n",
    "filtered_df = df[~df['Role'].isin(dropped_classes)].reset_index(drop=True)\n",
    "\n",
    "# Checking the updated role counts\n",
    "filtered_df['Role'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_df['Role'].value_counts())\n",
    "df = filtered_df.sample(n=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Splitting the data into features (X) and target (y)\n",
    "X = df['Features']\n",
    "y = df['Role']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def cleanResume(txt):\n",
    "    cleanText = re.sub('http\\S+\\s', ' ', txt)\n",
    "    cleanText = re.sub('RT|cc', ' ', cleanText)\n",
    "    cleanText = re.sub('#\\S+\\s', ' ', cleanText)\n",
    "    cleanText = re.sub('@\\S+', '  ', cleanText)  \n",
    "    cleanText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', cleanText)\n",
    "    cleanText = re.sub(r'[^\\x00-\\x7f]', ' ', cleanText) \n",
    "    cleanText = re.sub('\\s+', ' ', cleanText)\n",
    "    return cleanText\n",
    "\n",
    "\n",
    "# Prediction and Category Name\n",
    "def job_recommendation(resume_text):\n",
    "    resume_text= cleanResume(resume_text)\n",
    "    resume_tfidf = tfidf_vectorizer.transform([resume_text])\n",
    "    predicted_category = rf_classifier.predict(resume_tfidf)[0]\n",
    "    return predicted_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Category: Business Intelligence Analyst\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "resume_file = \"\"\"\n",
    "Data Scientist Summary\n",
    "Highly analytical and detail-oriented data scientist with 5+ years of experience in leveraging data to drive business decisions. Proficient in machine learning, statistical analysis, and data visualization. Skilled in Python, R, SQL, and big data technologies like Hadoop and Spark. Passionate about solving complex problems and delivering actionable insights through data-driven solutions.\n",
    "\n",
    "Highlights\n",
    "- Developed predictive models that improved customer retention by 20% for an e-commerce company.\n",
    "- Built and deployed machine learning pipelines using Python and Scikit-Learn, reducing processing time by 30%.\n",
    "- Expertise in data visualization tools like Tableau and Power BI, creating dashboards that informed executive decision-making.\n",
    "- Strong background in A/B testing and experimental design, leading to a 15% increase in conversion rates.\n",
    "- Published 2 research papers on natural language processing (NLP) and deep learning applications.\n",
    "\n",
    "Experience\n",
    "Company Name, City, State\n",
    "Senior Data Scientist | Jan 2020 – Present\n",
    "- Led a team of 4 data scientists in developing machine learning models for fraud detection, reducing fraudulent transactions by 25%.\n",
    "- Designed and implemented a recommendation system that increased cross-selling revenue by 18%.\n",
    "- Collaborated with engineering teams to integrate machine learning models into production systems.\n",
    "- Conducted workshops to upskill team members in advanced machine learning techniques.\n",
    "- Presented data-driven insights to stakeholders, influencing key business strategies.\n",
    "\n",
    "Company Name, City, State\n",
    "Data Scientist | Jun 2017 – Dec 2019\n",
    "- Analyzed large datasets to identify trends and patterns, providing actionable insights for marketing campaigns.\n",
    "- Built and maintained ETL pipelines using Apache Spark, improving data processing efficiency by 40%.\n",
    "- Developed NLP models for sentiment analysis, achieving 90% accuracy in customer feedback classification.\n",
    "- Automated reporting processes using Python scripts, saving 10 hours per week for the analytics team.\n",
    "- Partnered with product managers to define key performance indicators (KPIs) and track business metrics.\n",
    "\n",
    "Company Name, City, State\n",
    "Data Analyst | Sep 2015 – May 2017\n",
    "- Performed exploratory data analysis (EDA) to uncover insights from customer behavior data.\n",
    "- Created interactive dashboards in Tableau to visualize sales performance and market trends.\n",
    "- Assisted in the development of predictive models for customer segmentation.\n",
    "- Wrote SQL queries to extract and manipulate data from relational databases.\n",
    "- Supported data-driven decision-making by providing ad-hoc reports and analyses.\n",
    "\n",
    "Education\n",
    "Master of Science in Data Science\n",
    "University of Data Science, City, State | Graduated May 2015\n",
    "- Thesis: \"Applications of Deep Learning in Natural Language Processing\"\n",
    "- Relevant coursework: Machine Learning, Big Data Analytics, Statistical Modeling\n",
    "\n",
    "Bachelor of Science in Computer Science\n",
    "State University, City, State | Graduated May 2013\n",
    "- Graduated with honors (GPA: 3.9/4.0)\n",
    "- Relevant coursework: Data Structures, Algorithms, Database Systems\n",
    "\n",
    "Skills\n",
    "- Programming: Python, R, SQL, Java\n",
    "- Machine Learning: Scikit-Learn, TensorFlow, Keras, PyTorch\n",
    "- Big Data: Hadoop, Spark, Hive\n",
    "- Data Visualization: Tableau, Power BI, Matplotlib, Seaborn\n",
    "- Statistical Analysis: Hypothesis Testing, Regression, Bayesian Methods\n",
    "- Soft Skills: Problem-Solving, Communication, Team Collaboration\n",
    "\n",
    "Certifications\n",
    "- Certified Data Scientist (CDS) – Data Science Council of America (DASCA)\n",
    "- Google Professional Data Engineer\n",
    "- AWS Certified Machine Learning – Specialty\n",
    "\n",
    "Professional Affiliations\n",
    "- Member, Association for Computing Machinery (ACM)\n",
    "- Member, Data Science Association (DSA)\n",
    "- Member, Institute of Electrical and Electronics Engineers (IEEE)\n",
    "\n",
    "Publications\n",
    "- \"Deep Learning for Sentiment Analysis in Social Media,\" Journal of Data Science, 2019.\n",
    "- \"Applications of NLP in Customer Feedback Analysis,\" International Conference on Machine Learning, 2020.\n",
    "\n",
    "Languages\n",
    "- English (Fluent)\n",
    "- French (Conversational)\n",
    "\"\"\"\n",
    "predicted_category = job_recommendation(resume_file)\n",
    "print(\"Predicted Category:\", predicted_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(rf_classifier,open('../models/rf_classifier_job_recommendation.pkl','wb'))\n",
    "pickle.dump(tfidf_vectorizer,open('../models/tfidf_vectorizer_job_recommendation.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Cv_traitement",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
